{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660355ea",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2e43431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Set\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import logging\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fed8966",
   "metadata": {},
   "source": [
    "Configure logging and Ensure NLTK resources are downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7cf7cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "nltk.download('punkt', quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e081a38e",
   "metadata": {},
   "source": [
    "Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cbeeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Preprocessing function defined\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text: str) -> List[str]:\n",
    "    \"\"\"Preprocess text by tokenizing, keeping all meaningful words.\n",
    "\n",
    "    Args:\n",
    "        text: Input text string.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of processed words.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not text or not text.strip():\n",
    "            logger.warning(\"Empty or whitespace-only text provided for preprocessing\")\n",
    "            return []\n",
    "\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        processed = [word for word in tokens if word.isalnum() or word.isdigit()]\n",
    "        logger.debug(f\"Raw text: {text[:200]}\")\n",
    "        logger.debug(f\"Preprocessed tokens: {processed}\")\n",
    "        logger.debug(f\"Total processed tokens: {len(processed)}\")\n",
    "        if not processed:\n",
    "            logger.warning(\"No tokens remaining after preprocessing\")\n",
    "        return processed\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error preprocessing text: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "logger.info(\"Preprocessing function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141275f2",
   "metadata": {},
   "source": [
    "Vector Creation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c1de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Vector creation function defined\n"
     ]
    }
   ],
   "source": [
    "def create_word_vector(text: List[str]) -> Dict[str, int]:\n",
    "    \"\"\"Create a word frequency vector from processed text.\n",
    "\n",
    "    Args:\n",
    "        text: List of processed words.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, int]: Dictionary with words as keys and frequencies as values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not text:\n",
    "            logger.warning(\"Empty text provided for vector creation\")\n",
    "            return {}\n",
    "        vector = Counter(text)\n",
    "        logger.debug(f\"Word vector: {dict(vector)}\")\n",
    "        return vector\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating word vector: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "logger.info(\"Vector creation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a680d7ae",
   "metadata": {},
   "source": [
    "Cosine Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81fcb0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Cosine similarity function defined\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(vector1: Dict[str, int], vector2: Dict[str, int]) -> float:\n",
    "    \"\"\"Calculate cosine similarity between two word frequency vectors.\n",
    "\n",
    "    Args:\n",
    "        vector1: First word frequency vector.\n",
    "        vector2: Second word frequency vector.\n",
    "\n",
    "    Returns:\n",
    "        float: Cosine similarity value between 0 and 1.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not vector1 or not vector2:\n",
    "            logger.warning(\"One or both vectors are empty; returning 0 similarity\")\n",
    "            return 0.0\n",
    "\n",
    "        all_words: Set[str] = set(vector1.keys()).union(set(vector2.keys()))\n",
    "        if not all_words:\n",
    "            logger.warning(\"No words in combined vocabulary; returning 0 similarity\")\n",
    "            return 0.0\n",
    "\n",
    "        v1 = [vector1.get(word, 0) for word in all_words]\n",
    "        v2 = [vector2.get(word, 0) for word in all_words]\n",
    "\n",
    "        dot_product = sum(a * b for a, b in zip(v1, v2))\n",
    "        norm1 = math.sqrt(sum(a * a for a in v1))\n",
    "        norm2 = math.sqrt(sum(b * b for b in v2))\n",
    "\n",
    "        logger.debug(f\"Vector 1 values: {v1}\")\n",
    "        logger.debug(f\"Vector 2 values: {v2}\")\n",
    "        logger.debug(f\"Dot product: {dot_product}, Norm1: {norm1}, Norm2: {norm2}\")\n",
    "\n",
    "        if norm1 == 0 or norm2 == 0:\n",
    "            logger.warning(\"One or both vectors have zero magnitude; returning 0 similarity\")\n",
    "            return 0.0\n",
    "\n",
    "        similarity = dot_product / (norm1 * norm2)\n",
    "        logger.debug(f\"Cosine similarity calculated: {similarity}\")\n",
    "        return similarity\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating cosine similarity: {str(e)}\")\n",
    "        return 0.0\n",
    "\n",
    "logger.info(\"Cosine similarity function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a41fe12",
   "metadata": {},
   "source": [
    "Levenshtein Distance Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f85b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Levenshtein distance function defined\n"
     ]
    }
   ],
   "source": [
    "def levenshtein_distance(s1: str, s2: str) -> int:\n",
    "    \"\"\"Calculate Levenshtein distance between two strings.\n",
    "\n",
    "    Args:\n",
    "        s1: First string.\n",
    "        s2: Second string.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of single-character edits required.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if len(s1) < len(s2):\n",
    "            return levenshtein_distance(s2, s1)\n",
    "\n",
    "        if len(s2) == 0:\n",
    "            return len(s1)\n",
    "\n",
    "        previous_row = list(range(len(s2) + 1))\n",
    "        for i, c1 in enumerate(s1):\n",
    "            current_row = [i + 1]\n",
    "            for j, c2 in enumerate(s2):\n",
    "                insertions = previous_row[j + 1] + 1\n",
    "                deletions = current_row[j] + 1\n",
    "                substitutions = previous_row[j] + (c1 != c2)\n",
    "                current_row.append(min(insertions, deletions, substitutions))\n",
    "            previous_row = current_row\n",
    "\n",
    "        distance = previous_row[-1]\n",
    "        logger.debug(f\"Levenshtein distance calculated: {distance}\")\n",
    "        return distance\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating Levenshtein distance: {str(e)}\")\n",
    "        return -1\n",
    "\n",
    "logger.info(\"Levenshtein distance function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2800fc",
   "metadata": {},
   "source": [
    "Jaccard Index Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f8bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Jaccard index function defined\n"
     ]
    }
   ],
   "source": [
    "def jaccard_index(set1: Set[str], set2: Set[str]) -> float:\n",
    "    \"\"\"Calculate Jaccard Index between two sets of words.\n",
    "\n",
    "    Args:\n",
    "        set1: First set of words.\n",
    "        set2: Second set of words.\n",
    "\n",
    "    Returns:\n",
    "        float: Jaccard Index value between 0 and 1.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not set1 or not set2:\n",
    "            logger.warning(\"One or both sets are empty; returning 0 similarity\")\n",
    "            return 0.0\n",
    "\n",
    "        intersection = set1.intersection(set2)\n",
    "        union = set1.union(set2)\n",
    "        if not union:\n",
    "            logger.warning(\"No union of sets; returning 0 similarity\")\n",
    "            return 0.0\n",
    "\n",
    "        index = len(intersection) / len(union)\n",
    "        logger.debug(f\"Jaccard Index: {index}, Intersection: {intersection}, Union: {union}\")\n",
    "        return index\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating Jaccard Index: {str(e)}\")\n",
    "        return 0.0\n",
    "\n",
    "logger.info(\"Jaccard index function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a5d83c",
   "metadata": {},
   "source": [
    "Main Similarity Calculation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81aff51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Similarity calculation function defined\n"
     ]
    }
   ],
   "source": [
    "def calculate_similarities(job_text: str, cv_text: str) -> Dict[str, float]:\n",
    "    \"\"\"Calculate all similarities between job description and CV.\n",
    "\n",
    "    Args:\n",
    "        job_text: Text from a job description.\n",
    "        cv_text: Text from a CV.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: Dictionary with cosine similarity, Levenshtein distance, and Jaccard Index.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.debug(f\"Input job text: {job_text}\")\n",
    "        logger.debug(f\"Input CV text: {cv_text}\")\n",
    "\n",
    "        job_words = preprocess_text(job_text)\n",
    "        cv_words = preprocess_text(cv_text)\n",
    "\n",
    "        job_vector = create_word_vector(job_words)\n",
    "        cv_vector = create_word_vector(cv_words)\n",
    "        job_set = set(job_words)\n",
    "        cv_set = set(cv_words)\n",
    "\n",
    "        logger.debug(f\"Job vector: {job_vector}\")\n",
    "        logger.debug(f\"CV vector: {cv_vector}\")\n",
    "        logger.debug(f\"Job set: {job_set}\")\n",
    "        logger.debug(f\"CV set: {cv_set}\")\n",
    "\n",
    "        cosine_sim = cosine_similarity(job_vector, cv_vector)\n",
    "        levenshtein_dist = float(levenshtein_distance(job_text, cv_text))\n",
    "        jaccard_idx = jaccard_index(job_set, cv_set)\n",
    "\n",
    "        result = {\n",
    "            \"cosine_similarity\": cosine_sim,\n",
    "            \"levenshtein_distance\": levenshtein_dist,\n",
    "            \"jaccard_index\": jaccard_idx\n",
    "        }\n",
    "        logger.info(f\"Similarity results: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in similarity calculations: {str(e)}\")\n",
    "        return {\n",
    "            \"cosine_similarity\": 0.0,\n",
    "            \"levenshtein_distance\": -1.0,\n",
    "            \"jaccard_index\": 0.0\n",
    "        }\n",
    "\n",
    "logger.info(\"Similarity calculation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6430b9d4",
   "metadata": {},
   "source": [
    "Test Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2c71d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting similarity calculation API test\n",
      "INFO:__main__:Testing Cosine Similarity, Levenshtein Distance, and Jaccard Index calculation\n",
      "INFO:__main__:Similarity results: {'cosine_similarity': 0.7016464154456235, 'levenshtein_distance': 28.0, 'jaccard_index': 0.5333333333333333}\n",
      "INFO:__main__:Final similarity metrics: {'cosine_similarity': 0.7016464154456235, 'levenshtein_distance': 28.0, 'jaccard_index': 0.5333333333333333}\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Starting similarity calculation API test\")\n",
    "\n",
    "job_text: str = \"I am a lawyer with 5 years of legal experience in contract law\"\n",
    "cv_text: str = \"Lawyer with 5 years experience in legal contracts and law\"\n",
    "\n",
    "logger.info(\"Testing Cosine Similarity, Levenshtein Distance, and Jaccard Index calculation\")\n",
    "similarities: Dict[str, float] = calculate_similarities(job_text, cv_text)\n",
    "\n",
    "logger.info(f\"Final similarity metrics: {similarities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e9139d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
